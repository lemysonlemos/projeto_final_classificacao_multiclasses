# projeto_final_classificacao_multiclasses

# Projeto Final - Classifica√ß√£o de Textos: Multirr√≥tulo e Multiclasse

Este reposit√≥rio cont√©m dois projetos complementares de classifica√ß√£o de textos, utilizando a mesma base de dados, com foco em problemas de:

- **Classifica√ß√£o Multirr√≥tulo (Multilabel)**
- **Classifica√ß√£o Multiclasse (Multiclass)**

Ambos os projetos foram desenvolvidos em Python utilizando `TensorFlow` e `scikit-learn`.

---

## üìÅ Estrutura dos Projetos

### 1. Classifica√ß√£o Multirr√≥tulo

> Cada amostra pode possuir **mais de um r√≥tulo**.

- **M√©tricas Avaliadas**:
  - `Precision@K`
  - `Recall` m√©dio por amostra
  - `F1-score` m√©dio por amostra
  - `Hamming Loss`

#### ‚úÖ Resultados obtidos:

| Modelo                      | Precision | Recall | F1     | Hamming Loss |
|----------------------------|-----------|--------|--------|---------------|
| Modelo Base                | 0.7900    | 0.5377 | 0.5959 | 0.0198        |
| Modelo Base + PCA          | 0.7073    | 0.5899 | 0.5992 | 0.0220        |
| Modelo Base + Blocos       | 0.8046    | 0.4004 | 0.5013 | 0.0212        |
| Modelo Customizado         | 0.4600    | 0.1820 | 0.2505 | 0.0267        |

---

### 2. Classifica√ß√£o Multiclasse

> Cada amostra pertence **a apenas um r√≥tulo**.

- A base de dados multirr√≥tulo foi adaptada com uma estrat√©gia de **remapeamento para r√≥tulo √∫nico**.
- **Sa√≠da**: Softmax sobre o total de classes.
- **Fun√ß√£o de Perda**: `sparse_categorical_crossentropy`.
- **M√©tricas Avaliadas**:
  - `Precision`
  - `Recall`
  - `F1-score` macro

#### ‚úÖ Resultados obtidos:

| Modelo                      | Precision | Recall | F1     |
|----------------------------|-----------|--------|--------|
| Modelo Base                | 0.5355    | 0.6100 | 0.5515 |
| Modelo Base + Blocos       | 0.5952    | 0.6200 | 0.5898 |
| Modelo Base + PCA          | 0.4703    | 0.5850 | 0.5019 |
| Modelo Customizado         | 0.4832    | 0.5050 | 0.4264 |

---

## üß† Arquiteturas dos Modelos

- **Modelo Base**: MLP simples com uma camada densa.
- **Modelo Base + PCA**: Redu√ß√£o dimensional das features de entrada.
- **Modelo Base + Blocos**: Uso de camadas intermedi√°rias com Dropout e BatchNormalization.
- **Modelo Customizado**: Arquitetura mais profunda com ajuste de learning rate, n√∫mero de neur√¥nios, dropout e regulariza√ß√µes.

---

## üìä Visualiza√ß√µes e Avalia√ß√£o

Todos os notebooks apresentam:
- C√≥digo comentado e organizado por se√ß√µes.
- Avalia√ß√£o por √©poca com callback customizado.
- Gr√°ficos de perda, m√©tricas e matriz de confus√£o (multiclasse).
- Se√ß√£o final com **c√≥digo completo para execu√ß√£o direta**.

---

Conclus√£o
O projeto alcan√ßou com sucesso os objetivos propostos para os dois cen√°rios de classifica√ß√£o: multirr√≥tulo e multiclasse.

A base utilizada foi o conjunto RCV1 (Reuters Corpus Volume 1), carregado diretamente via sklearn.datasets.fetch_rcv1. Essa base √© composta por milhares de not√≠cias jornal√≠sticas com m√∫ltiplas categorias por documento ‚Äî o que a torna ideal para problemas de classifica√ß√£o multirr√≥tulo. Para este projeto, foi utilizado um subconjunto de 1.000 amostras para facilitar a prototipa√ß√£o e testes computacionais.

Na classifica√ß√£o multirr√≥tulo, os modelos conseguiram prever m√∫ltiplos r√≥tulos por amostra com boa precis√£o e baixa taxa de erro (Hamming Loss). O modelo com blocos adicionais (BatchNorm e Dropout) foi o que apresentou melhor equil√≠brio entre precis√£o e robustez.

Para a classifica√ß√£o multiclasse, a base multirr√≥tulo foi adaptada convertendo cada amostra para um √∫nico r√≥tulo dominante. O remapeamento foi eficaz, e os modelos apresentaram resultados satisfat√≥rios, com destaque para o modelo com camadas ocultas adicionais, que obteve o melhor desempenho geral.

Apesar das limita√ß√µes impostas pelo n√∫mero reduzido de amostras, os resultados demonstraram que as arquiteturas propostas s√£o capazes de aprender representa√ß√µes √∫teis e generaliz√°veis. Assim, o experimento foi bem-sucedido, comprovando a aplicabilidade de redes neurais profundas tanto para problemas de m√∫ltiplos r√≥tulos simult√¢neos quanto para classifica√ß√£o exclusiva por classe.

