{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, hamming_loss\n",
        "import itertools\n",
        "\n",
        "# --- Simular dataset ---\n",
        "# Embeddings concatenados (video=1024, audio=128) = 1152 features\n",
        "# Multilabel com 4800 classes (multi-hot)\n",
        "\n",
        "num_samples = 1000\n",
        "num_features = 1152\n",
        "num_classes = 4800\n",
        "\n",
        "# Simula entradas\n",
        "X = np.random.rand(num_samples, num_features).astype(np.float32)\n",
        "\n",
        "# Simula labels multilabel multi-hot (0/1)\n",
        "Y = np.random.randint(0, 2, size=(num_samples, num_classes)).astype(np.float32)\n",
        "\n",
        "# --- Dividir treino/validação ---\n",
        "split = int(num_samples * 0.8)\n",
        "X_train, X_val = X[:split], X[split:]\n",
        "Y_train, Y_val = Y[:split], Y[split:]\n",
        "\n",
        "# --- Funções métricas multilabel ---\n",
        "def precision_at_k(y_true, y_pred, k=20):\n",
        "    top_k_preds = tf.math.top_k(y_pred, k=k).indices\n",
        "    precisions = []\n",
        "    for i in range(y_true.shape[0]):\n",
        "        true_labels = tf.where(y_true[i] > 0)[:,0]\n",
        "        # Converter para int32 para evitar erro de tipo\n",
        "        true_labels = tf.cast(true_labels, tf.int32)\n",
        "        pred_labels = tf.cast(top_k_preds[i], tf.int32)\n",
        "        intersect = tf.sets.intersection(tf.expand_dims(true_labels,0), tf.expand_dims(pred_labels,0))\n",
        "        precisions.append(tf.size(intersect.values)/k)\n",
        "    return tf.reduce_mean(precisions)\n",
        "\n",
        "def multilabel_metrics(y_true, y_pred, threshold=0.5):\n",
        "    y_pred_bin = (y_pred >= threshold).numpy().astype(int)\n",
        "    y_true_np = y_true.numpy().astype(int)\n",
        "\n",
        "    precision = precision_score(y_true_np, y_pred_bin, average='samples', zero_division=0)\n",
        "    recall = recall_score(y_true_np, y_pred_bin, average='samples', zero_division=0)\n",
        "    f1 = f1_score(y_true_np, y_pred_bin, average='samples', zero_division=0)\n",
        "    hamming = hamming_loss(y_true_np, y_pred_bin)\n",
        "    return precision, recall, f1, hamming\n",
        "\n",
        "# --- 1. Modelo Base ---\n",
        "def build_base_model(input_dim, output_dim):\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(input_dim,)),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.Dense(output_dim, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# --- 2. Modelo Base + variações ---\n",
        "def apply_pca(X_train, X_val, n_components=256):\n",
        "    pca = PCA(n_components=n_components)\n",
        "    X_train_pca = pca.fit_transform(X_train)\n",
        "    X_val_pca = pca.transform(X_val)\n",
        "    return X_train_pca, X_val_pca\n",
        "\n",
        "# --- 3. Modelo Base + Blocos ---\n",
        "def build_model_with_blocks(input_dim, output_dim):\n",
        "    inputs = layers.Input(shape=(input_dim,))\n",
        "    x = layers.Dense(1024)(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.Dense(512)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    outputs = layers.Dense(output_dim, activation='sigmoid')(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# --- 4. Seu Modelo (exemplo com mais camadas e tuning) ---\n",
        "def build_custom_model(input_dim, output_dim, lr=1e-4):\n",
        "    inputs = layers.Input(shape=(input_dim,))\n",
        "    x = layers.Dense(2048, activation='relu')(inputs)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "    x = layers.Dense(1024, activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.Dense(512, activation='relu')(x)\n",
        "    outputs = layers.Dense(output_dim, activation='sigmoid')(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# --- Callbacks para métricas customizadas ---\n",
        "class MetricsCallback(callbacks.Callback):\n",
        "    def __init__(self, validation_data):\n",
        "        super().__init__()\n",
        "        self.X_val, self.Y_val = validation_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        y_pred = self.model.predict(self.X_val, verbose=0)\n",
        "        p_at_20 = precision_at_k(self.Y_val, tf.convert_to_tensor(y_pred), k=20).numpy()\n",
        "        precision, recall, f1, hamming = multilabel_metrics(tf.convert_to_tensor(self.Y_val), tf.convert_to_tensor(y_pred))\n",
        "\n",
        "        print(f\"Epoch {epoch+1} - Precision@20: {p_at_20:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, Hamming Loss: {hamming:.4f}\")\n",
        "\n",
        "# --- Treinar Modelo Base ---\n",
        "print(\"Treinando Modelo Base\")\n",
        "model_base = build_base_model(num_features, num_classes)\n",
        "model_base.fit(\n",
        "    X_train, Y_train,\n",
        "    epochs=5,\n",
        "    batch_size=32,\n",
        "    callbacks=[MetricsCallback((X_val, Y_val))]\n",
        ")\n",
        "\n",
        "# --- Treinar Modelo Base + PCA (variações) ---\n",
        "print(\"\\nTreinando Modelo Base + PCA\")\n",
        "X_train_pca, X_val_pca = apply_pca(X_train, X_val, n_components=256)\n",
        "model_base_pca = build_base_model(256, num_classes)\n",
        "model_base_pca.fit(\n",
        "    X_train_pca, Y_train,\n",
        "    epochs=5,\n",
        "    batch_size=32,\n",
        "    callbacks=[MetricsCallback((X_val_pca, Y_val))]\n",
        ")\n",
        "\n",
        "# --- Treinar Modelo Base + Blocos ---\n",
        "print(\"\\nTreinando Modelo Base + Blocos\")\n",
        "model_blocks = build_model_with_blocks(num_features, num_classes)\n",
        "model_blocks.fit(\n",
        "    X_train, Y_train,\n",
        "    epochs=5,\n",
        "    batch_size=32,\n",
        "    callbacks=[MetricsCallback((X_val, Y_val))]\n",
        ")\n",
        "\n",
        "# --- Treinar Seu Modelo ---\n",
        "print(\"\\nTreinando Seu Modelo\")\n",
        "model_custom = build_custom_model(num_features, num_classes, lr=5e-5)\n",
        "model_custom.fit(\n",
        "    X_train, Y_train,\n",
        "    epochs=5,\n",
        "    batch_size=32,\n",
        "    callbacks=[MetricsCallback((X_val, Y_val))]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghtw5Js4CvFy",
        "outputId": "d9d5fc72-51fb-4770-9d7b-21f2eea769bd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treinando Modelo Base\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.6943Epoch 1 - Precision@20: 0.5032, Precision: 0.4993, Recall: 0.4973, F1: 0.4983, Hamming Loss: 0.5001\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 170ms/step - loss: 0.6942\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.6930Epoch 2 - Precision@20: 0.5165, Precision: 0.4984, Recall: 0.4953, F1: 0.4968, Hamming Loss: 0.5010\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - loss: 0.6930\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.6929Epoch 3 - Precision@20: 0.5005, Precision: 0.4991, Recall: 0.4969, F1: 0.4980, Hamming Loss: 0.5004\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 0.6929\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.6927Epoch 4 - Precision@20: 0.5092, Precision: 0.4993, Recall: 0.4959, F1: 0.4975, Hamming Loss: 0.5002\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - loss: 0.6927\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.6925Epoch 5 - Precision@20: 0.5142, Precision: 0.4991, Recall: 0.4992, F1: 0.4991, Hamming Loss: 0.5004\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.6925\n",
            "\n",
            "Treinando Modelo Base + PCA\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.6953Epoch 1 - Precision@20: 0.4980, Precision: 0.4995, Recall: 0.4942, F1: 0.4968, Hamming Loss: 0.4999\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 0.6953\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.6859Epoch 2 - Precision@20: 0.5005, Precision: 0.4995, Recall: 0.4976, F1: 0.4985, Hamming Loss: 0.5000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - loss: 0.6859\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.6779Epoch 3 - Precision@20: 0.5108, Precision: 0.4995, Recall: 0.4974, F1: 0.4984, Hamming Loss: 0.4999\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - loss: 0.6779\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.6675Epoch 4 - Precision@20: 0.5105, Precision: 0.4993, Recall: 0.4975, F1: 0.4984, Hamming Loss: 0.5001\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - loss: 0.6675\n",
            "Epoch 5/5\n",
            "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.6542Epoch 5 - Precision@20: 0.5015, Precision: 0.4990, Recall: 0.4982, F1: 0.4986, Hamming Loss: 0.5004\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - loss: 0.6542\n",
            "\n",
            "Treinando Modelo Base + Blocos\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.7045Epoch 1 - Precision@20: 0.5000, Precision: 0.5000, Recall: 0.4991, F1: 0.4995, Hamming Loss: 0.4995\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 151ms/step - loss: 0.7044\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.6877Epoch 2 - Precision@20: 0.4940, Precision: 0.4997, Recall: 0.4933, F1: 0.4964, Hamming Loss: 0.4998\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - loss: 0.6877\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.6739Epoch 3 - Precision@20: 0.5025, Precision: 0.5000, Recall: 0.4976, F1: 0.4988, Hamming Loss: 0.4995\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - loss: 0.6739\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.6610Epoch 4 - Precision@20: 0.5030, Precision: 0.5000, Recall: 0.4943, F1: 0.4971, Hamming Loss: 0.4995\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 154ms/step - loss: 0.6610\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.6469Epoch 5 - Precision@20: 0.4917, Precision: 0.4992, Recall: 0.4948, F1: 0.4969, Hamming Loss: 0.5003\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 142ms/step - loss: 0.6469\n",
            "\n",
            "Treinando Seu Modelo\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.7118Epoch 1 - Precision@20: 0.4928, Precision: 0.4987, Recall: 0.5031, F1: 0.5008, Hamming Loss: 0.5008\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 206ms/step - loss: 0.7118\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.7064Epoch 2 - Precision@20: 0.4988, Precision: 0.4983, Recall: 0.5018, F1: 0.5000, Hamming Loss: 0.5012\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.7064\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.7039Epoch 3 - Precision@20: 0.4967, Precision: 0.4992, Recall: 0.5025, F1: 0.5008, Hamming Loss: 0.5003\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.7039\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.7025Epoch 4 - Precision@20: 0.4977, Precision: 0.4993, Recall: 0.5020, F1: 0.5006, Hamming Loss: 0.5002\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 195ms/step - loss: 0.7025\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.7016Epoch 5 - Precision@20: 0.4960, Precision: 0.4991, Recall: 0.4984, F1: 0.4987, Hamming Loss: 0.5004\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.7016\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b274dfefd10>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DpCM9xWnBdKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A_HkNOPkBdTY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}